# -*- coding: utf-8 -*-
"""Final_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZIEf4_pBChFZed4B0FMD7OM6BBTKfkjc
"""

import zipfile
import os

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten , Dropout , Conv2D , MaxPooling2D
from tensorflow.keras.preprocessing  import image_dataset_from_directory

zip_file_path = '/content/archive (2).zip'
extract_folder = 'extracted_images'
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extract_folder)

train_dir = '/content/extracted_images/train'
test_dir = '/content/extracted_images/test'

#train_gen = ImageDataGenerator(rescale=1./255)
#test_gen = ImageDataGenerator(rescale=1./255)

#train_dataset = train_gen.flow_from_directory(
   # train_dir,
    #target_size=(48, 48),
    #batch_size=64,
    #class_mode='sparse' ,
    #color_mode='grayscale'
#)

#test_dataset = test_gen.flow_from_directory(
    #test_dir,
    #target_size=(48, 48),
    #batch_size=64,
    #class_mode='sparse',
    #color_mode='grayscale'
#)

train_dataset = image_dataset_from_directory(
    train_dir,
    color_mode='grayscale',
    batch_size = 64,
    image_size = (48,48))

test_dataset = image_dataset_from_directory(
    test_dir,
    color_mode='grayscale',
    batch_size = 64,
    image_size = (48,48))

def normalize(img,label):
  return img/255.0,label

  train_dataset = train_dataset.map(normalize)
  test_dataset = test_dataset.map(normalize)

model = Sequential([
    Conv2D(256,(3,3),activation='relu',input_shape=(48,48,1)),
    MaxPooling2D((2,2)),
    Conv2D(128,(3,3),activation='relu',input_shape=(48,48,1)),
    MaxPooling2D((2,2)),
    Conv2D(64,(3,3),activation='relu'),
    MaxPooling2D((2,2)),
    Conv2D(32,(3,3),activation='relu'),
    MaxPooling2D((2,2)),
    #Conv2D(16,(3,3),activation='relu'),
    #MaxPooling2D((2,2)),
    Flatten(),
    Dense(256,activation='relu'),
    Dropout(0.1),
    Dense(128,activation='relu'),
    Dropout(0.1),
    Dense(64,activation='relu'),
    Dropout(0.1),
    Dense(32,activation='relu'),
    Dropout(0.1),
    #Dense(10, activation='sigmoid'),
    Dense(7,activation='softmax')
])



model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])

from tensorflow.keras.callbacks import EarlyStopping
early = EarlyStopping(monitor='accuracy',patience=3)

model.fit(train_dataset,epochs=100)

model.save('model.keras')



